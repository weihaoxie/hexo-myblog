<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[卷积神经网络的基本概念]]></title>
    <url>%2Fpost%2F0.html</url>
    <content type="text"><![CDATA[一、深度学习简介 深度学习是机器学习的一个子领域，它使用多层非线性信息处理及抽象，用于监督和非监督的特征学习和表示、分类及模式识别。深度学习在不同的学习任务上都取得了很大的成功,特别是在Imagenet的图像分类任务和LFW的人脸识别任务上更是超过了人类水平。相比于传统方法，深度学习具有很多优势。首先深度学习通用性更强，而传统方法针对不同的任务需要设计不同的特征。深度学习相较于传统方法可以自动从原始数据中提取特征，所以同个算法可以应用到各种类似的任务中来，比如目标检测任务，它可以同时用于人脸检测，行人检测，一般物体检测任务上。其次深度学习学习的特征具有很强的迁移能力，比如它在ImagetNet分类任务上学习的特征，在目标检测任务上也可以获得非常好的效果。最后一个优势是它的工程开发、优化、维护成本较低。深度学习计算主要是卷积和矩阵乘，针对这种计算优化，所有的深度学习算法都可以提升性能；另外，通过组合现有的层，我们可以实现大量复杂网络结构和算法，开发维护成本也很低。随着深度学习的发展，当前也存在着很多种不同类型的网络体系结构，如深度自编码网络、卷积神经网络、时间递归神经网络等。其中应用最广泛的是卷积神经网络。 二、卷积神经网络的发展过程 卷积神经网络是一种深度学习网络结构，它的发明灵感来自于生物的自然视觉感知机制。在1990年，LeCun等人$^{[1]}$发表了开创性的论文建立了CNN的现代框架，并随后提出了对它的改进$^{[2]}$。他们开发了一个多层的人工神经网络叫做LeNet-5，用于识别手写体数字图片。与其它神经网络类似，LeNet-5具有多个网络层，并且可以通过反向传播算法$^{[3]}$来训练。它可以从输入图片中学习到有效的表示，这也让它可以直接通过原图来进行识别，而不需要先对图片提取特征。但是由于当时缺少大规模的训练数据以及受到计算能力的限制，他们的网络在更复杂的问题上(如大规模的图片和视频分类任务)无法表现得很好。 自2006年以来，很多的方法已经被开发出来用于改进卷积神经网络$^{[5-8]}$。其中最著名的是Krizhevsky等人提出的经典的CNN体系结构，AlexNet$^{[6]}$，该体系结构在图像分类任务上的性能大大超过了先前的方法，在图像分类任务上的top-1和top-5错误率分别从47.1%和28.2%降低到37.5%和17.0%。AlexNet在网络结构上与LeNet-5类似，但是网络结构比LeNet-5更加深。随着AlexNet的成功，很多的工作被提出来改进它的性能。其中，最有代表性的工作是ZFNet$^{[9]}$，VGGNet$^{[7]}$, GoogleNet$^{[8]}$,和ResNet$^{[10]}$。随着更多改进方法的提出，当前卷积神经网络在很多任务上都获得很高的性能，并且在某些任务中超过了人类水平。 三、卷积神经网络的基本部件及训练方法简介 我们将输入数据输入到网络中，并经过卷积层、池化层、全连接层，最后到达输出层输出结果的过程称为前向传播。前向传播得到的估计值通常与实际结果会有误差，模型的训练过程就是不断缩小估计值与实际值之间的误差的过程。在这个过程中我们利用损失函数来衡量估计值和实际结果的误差带来的损失，并试图让该损失尽可能小，为此我们将误差带来的损失从输出层向隐含层传播，直至传播到输入层，这个过程称为反向传播。在传播过程中通过某种误差调整策略，如随机梯度下降，调整模型参数，使得模型误差减小。整个模型的训练过程就是不断迭代前向传播，反向传播并调整模型参数这个过程，直至最后模型收敛。在模型收敛之后，模型的每次预测过程就是一次前向传播过程。虽然当前存在很多不同的卷积神经网络体系结构，但是它们的基本部件是很相似的。如LeNet-5，它主要包含3种部件，卷积层、池化层和全连接层。下面给出了卷积神经网络的各个部件及其训练方法的简单介绍。 图一.LeNet-5网络结构 卷积层 卷积层的目的是学习输入的特征表示，如图一所示，卷积层主要由多个卷积核构成，每个卷积核被用于计算不同的特征图。图二给出了卷积计算的一个例子，其中图二(a)为卷积核，图二(b)中蓝色矩阵为输入的特征图，绿色矩阵为利用图二(a)中的卷积核对输入特征图进行卷积计算的结果。输出的矩阵中的每个神经元与输入特征图的局部区域相连，这个局部区域就是当前神经元在上一层的感受野。输出矩阵的计算方式是利用卷积核对每个局部区域进行卷积，即逐元素相乘再相加。在得到卷积结果之后，新的特征图可以通过对每个从局部区域卷积计算得到的神经元应用非线性激活函数得到。这里值得注意的是，同个特征图的生成过程中，输入的多个局部区域共享同个卷积核。最终多个特征图的生成，则是由多个不同的卷积核计算得到。我们把在第l层的第k个特征图中的第(i,j)个位置(这里(i,j)表示第i行第j列)的特征值表示为$z^l_{i,j,k}$，则： 其中w表示第l层第k个滤波器的权重，b表示该滤波器对应的偏置项，x表示当前响应值对应的输入块，其中心位置对应特征图中的第(i,j)个位置。这里w为当前特征图中每个特征值所共享。这种权重共享方式具有多种优势，它可以降低模型复杂度，并且可以让网络更加容易训练。在卷积神经网络中引入非线性激活函数，可以让多层网络学习到非线性特征。用$z^l_{i,j,k}$表示非线性激活函数，则卷积特征值的激活值$a^l_{i,j,k}$可以表示为：经典的激活函数是sigmoid、tanh、ReLU和Leaky ReLU，图三中给出了这四种常见的激活函数。图四中显示了两个卷积层从数字图片7中学习到的特征图，其中左边为第一层卷积层的特征图，大小为6X28X28，右边为第三层卷积层的特征图，大小为16X10X10。从特征图可以看出底层卷积核主要用于学习低层次的信息，如边缘和曲线，而更高层的卷积核则用于学习更加抽象的信息。通过叠加多个卷积层和池化层，我们可以逐渐提取到更加高层次的特征表示。 图二 (a).卷积核示例 图二(b).卷积计算示例 图三.常用的激活函数 图四.从数字图片7中学到的特征 池化层 池化层通过减少特征图分辨率的方式让网络具有平移和旋转不变性。它经常放在两个卷积层之间。典型的池化操作是平均池化和最大池化。图五给出了池化操作的例子，其中图五(a)为平均池化，图五(b)为最大池化。池化层的每个特征图与它前一层的卷积层对应的特征图相连接。用$pool(.)$表示池化函数，对于卷积层的每个特征图$a^l_{:,:,k}$，对应的池化层的特征值可以表示为：其中$R_{i,j}$是卷积层特征图中第(i,j)个位置周围的一个局部区域。平均池化取池化区域的平均值，而最大池化则是取池化区域的最大值。 图五(a) 平均池化示例 图五(b) 最大池化示例 全连接层 在经过多个卷积和池化层之后，可能会连接一个或者多个全连接层来进行高层次的推理。图六给出了全连接层的例子，它们将前一层的所有的神经元作为输入，并将它们与当前层的每个神经元相连接，通过这种方式来生成全局的语义信息。这里的全连接层并不是必须的，它有时候也可以用1X1的卷积层来替代。 图六.全链接层示例 输出层及损失函数 卷积神经网络的最后一层是输出层。对于分类任务，最常用的是softmax操作。另一个比较常用的方法是svm，它可以结合卷积层的特征来处理多种不同的分类任务。用K表示类别数，则其对应的softmax函数可以表示为： 其中$\sigma(z)_j）$表示第j个类别的概率。对于回归任务，输出层一般为普通神经元。用$\theta$表示所有可学习的参数(比如卷积核的权重和偏置项)，对于具体任务的最优参数，可以通过优化其对应的损失函数来得到。假设我们有N个有标签的训练样本数据，将其表示为{(x(n),y(n))};nЄ{[1,…,N]}，这里x(n)表示第n个输入数据，y(n)是其对应的标签，用o(n)表示卷积神经网络的输出，则其损失函数可以表示为：对于分类任务，损失函数一般选择交叉熵损失函数；对于回归任务，则一般为均方误差。 图七.带有一层隐含层的前馈神经网络 ５. 反向传播算法 训练卷积神经网络是一个全局优化的问题，通过最小化损失函数，我们可以找到最合适的参数集。通常我们采用随机梯度下降方法来优化CNN网络。CNN网络中梯度的计算主要采用了反向传播算法，其中主要利用了链式法则来对不同网络层的权重进行求导。下面给出反向传播的一个简单例子，假设我们的网络结构如图七所示并假设损失函数为均方误差，则损失函数可以表示为： 其中x是输入数据，y是其对应的标签；σ为激活函数，这里选取sigmoid函数为激活函数；W1，b1、W2，b2分别为第一层和第二层的权重和偏置项。我们将中间变量定义为： 则其前向传播过程如下： 对应的中间变量的梯度即反向传播如下: 通过链式法则可以很容易计算到各个参数的梯度，如W2和b2的梯度： [1] B. B. Le Cun, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, L. D. Jackel, Handwritten digit recognition with a back-propagation network, in: Proceedings of the Advances in Neural Information Processing Systems (NIPS), 1989, pp. 396–404.[2] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document recognition, Proceedings of IEEE 86 (11) (1998) 2278–2324.[3] R. Hecht-Nielsen, Theory of the backpropagation neural network, Neural Networks 1 (Supplement-1) (1988) 445–448.[4] W. Zhang, K. Itoh, J. Tanida, Y. Ichioka, Parallel distributed processing model with local space-invariant interconnections and its optical architecture, Applied optics 29 (32) (1990) 4790–4797.[5] X.-X. Niu, C. Y. Suen, A novel hybrid cnn–svm classifier for recognizing handwritten digits, Pattern Recognition 45 (4) (2012) 1318–1325.[6] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al., Imagenet large scale visual recognition challenge, International Journal of Conflict and Violence (IJCV) 115 (3) (2015) 211–252.[7] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition, in: Proceedings of the International Conference on Learning Representations (ICLR), 2015.[8] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 1–9.[9] M. D. Zeiler, R. Fergus, Visualizing and understanding convolutional networks, in: Proceedings of the European Conference on Computer Vision (ECCV), 2014, pp. 818–833.[10] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770–778.]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>convolution neural network</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CT-Realistic Lung Nodule Simulation from 3D Conditional Generative Adversarial Networks for Robust Lung Segmentation]]></title>
    <url>%2Fpost%2Fd5dc028e.html</url>
    <content type="text"><![CDATA[该论文发表于MICCAI2018 动机 在医疗图像领域，数据难获取，而且类内存在着很大的差异。为了缓解数据问题，作者在这篇文章中调查了通过仿真出来的数据，是否能够改善P-HNN模型在肺结节分割任务上的效果。 主要创新点 为了生成仿真数据，作者使用了GAN模型，有效地学习肺结节在3D空间中的属性分布。 为了让仿真的结节能够更好的融入到背景中去，作者使用了真结节的背景信息，即把真结节从图片中抠走。 最后为了能够进一步让结节看起来更加的真实作者提出了一个新颖的multi-mask重构loss. 具体实现 1.3D CGAN 网络结构 生成网络的输入是消除掉中心结节但是包含结节背景信息的图像。通过编码和解码过程，生成网络试图恢复消除掉的中心结节。 判别器的输入包括了扣掉中心结节的图片以及原始图片。 在生成网络的解码器的前两个卷积层作者加入了dropout. 作者在网络中利用strided卷积代替了pooling层。 包括生成网络的编码器，以及判别网络。并在strided 卷积后使用了Leaky relu激活函数。 在生成器的最后一层作者使用了Tanh激活函数 2.模型loss CGAN loss multi-mask L1 loss 这里的M表示消除掉的结节位置，N是对M进行膨胀后的结果。这里的multi-mask是指对消除掉的结节位置的重构loss以及对其膨胀后膨胀位置像素的重构loss，分别赋予不同的loss 权重。比较合适的是3到6个。这里作者给前者赋予1.0，后者赋予5.0. 这个模型的loss由这两部分加权构成 loss包括了两部分，一部分是普通的CGAN loss；另一部分是multi-mask loss。这两部分的权重分别为1.0和100.0. 3.相关参数 作者使用了标准的GAN训练方法，交替优化G和D。 在训练G的时候，作者通过去最大化logD(x,G(x)),而不是去最小化log(1-D(x,G(x)))。 作者使用了Adam优化方法，并设置初始学习率为0.0001，对于生成器动量参数设置为0.5，对于判别器动量参数设置为0.999。 4.数据和结果作者使用了LIDC数据集对GAN模型进行训练1.真实结节从ct图像中crop出来，crop的3个纬度的是结节直径的3到3.5倍大。最后将crop出来的图片缩放到64X64X64。2.消除掉结节的输入图片，由真实结节图片消除掉中心直径为32的球体生成。3.对于结节直接小于5mm的，不用于训练GAN.(c) 用全图的L1loss,不用判别网络(d) 用了GAN和全图的L1 loss(e) 用了GAN和中心消除位置的L1 loss(f) 用了GAN和multi-mask L1 loss 利用训练好的GAN模型生成一些仿真结节，用于fine-tune P-HNN模型P-HNN模型在之前的实验中对于在肺壁的结节分割效果较差，主要原因是训练数据中缺少肺壁附近的结节。 作者首先从LIDC数据集中挑选了34张图，了解数据中缺少的外围结节大致是如何的。 然后从相对健康的CT影像中挑选42个。并从其中随机挑选了30个类似的位置。每个位置距离肺壁距离在8到20mm之间。crop图片的大小为32到80mm之间。 接着将crop的图片缩放到64X64X64。生成仿真数据之后，再将其缩放回去，然后黏贴回原来的位置。 最后利用他们来fine-tune P-HNN模型。 最后的结果显示，生成的结节确实可以提高分割效果。]]></content>
      <categories>
        <category>深度学习</category>
        <category>医学图像处理</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>lung nodule</tag>
        <tag>segmentation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[object detection]]></title>
    <url>%2Fpost%2F4ec81054.html</url>
    <content type="text"><![CDATA[object detection（rcnn,the way to endtoend）本文主要简单介绍了rcnn如何一步步改进到支持端到端训练的faster-rcnn。 基础概念 mAP（mean average precision） precision：检测出相关的内容占检测出的内容的比例。 average precision：举个例子，比如说当前文档相关的主题有5个，检测出了3个，其中3个相关的主题rank分别为2,3,4，则这个文档的average precision就是(1/2+2/3+3/4+0+0)/5 。 mAP:则是每个文档的average precision的平均值。这里的文档对应于目标检测的每张图片，而相关主题则对应到图片中目标的个数 IoU（交并比） 两个区域的交集比上两个区域的并集 non maxinum supression 与得分最高的区域的IOU高于某个阈值时，将其排除掉 基于region proposeal加classification这一框架的几个重要工作1.rcnn 几个重要的创新 selection search提取候选区域 利用cnn 提取重要的特征（需要将特征保存到硬盘中，用于svm的训练） 利用svm对不同的候选框进行分类 利用回归来获取更加准确的位置 缺点： 训练需要分成多个阶段完成 训练和存储代价大 检测速度缓慢 2.spp-net 几个重要的贡献 rcnn速度缓慢的原因是它需要分别对每个proposal提取特征，而没有共享计算 输入整张图片，然后利用spp层提取不同尺度大小的featuremap，最后将它们级联起来，最后输出一个特定维度的特征向量。 spp-net使得rcnn在检测的时候提升了10到100倍。训练速度提升了3倍。 缺点 训练仍然需要多个阶段。仍然需要提取特征训练svm； 最后仍然需要利用回归模型来获取更加精确的定位。 需要将特征保存到硬盘中。 网络训练的时候梯度没法穿过spp层。 3.fast rcnn 解决需要将同张图的每个候选区域分别输入网络提取特征的问题直接输入原图，并利用cnn以及roipooling来提取每个roi区域的特征，并利用cnn对每个roi区域进行分类以及定位 roipooling层：单尺度的ssp层，输出特定大小的特征向量，类似于根据情况调整pooling层的kenal size。 多任务的loss：softmax层以及bounding box 回归 几个重要的贡献 提升了训练以及检测的速度。 训练只需要单个阶段就可以完成。使用了多任务的loss层。 可以调整网络的所有层。 不需要将特征保存到硬盘中 缺点： 仍然需要利用selection search 4.faster rcnn 提出了利用PRN来提取候选区域，并让PRN与fast rcnn共享网络。使得目标检测成为真正的一种endtoend的方式，并将速度进一步提升到可以进行实时检测的目的。]]></content>
      <categories>
        <category>深度学习</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>object detection</tag>
        <tag>rcnn</tag>
        <tag>spp-net</tag>
        <tag>fast rcnn</tag>
        <tag>faster rcnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime基础用法汇总]]></title>
    <url>%2Fpost%2Ff7b78535.html</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sublime由于支持多种插件的功能扩展，以及其优秀的编辑能力，得到了越来越多人特别是linux平台下的程序开发人员的青睐。但是想要发挥他强大的功能优势，还是需要学习以及熟悉这些功能，在这里整理了网上关于sublime插件基础用法的相关资料，供需要的人查看。sublime简明教程简书上有人整理的sublime学习资源]]></content>
  </entry>
  <entry>
    <title><![CDATA[利用git来管理各种文档]]></title>
    <url>%2Fpost%2F6de20b39.html</url>
    <content type="text"></content>
      <categories>
        <category>工作环境</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[terminator+tmux打造超级终端]]></title>
    <url>%2Fpost%2F12fd4503.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[利用sublime文本编辑工具和markdown标记语言写印象笔记]]></title>
    <url>%2Fpost%2F78cc5777.html</url>
    <content type="text"></content>
      <categories>
        <category>工作环境</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建属于你自己的工作环境]]></title>
    <url>%2Fpost%2Fd9ff40b9.html</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文主要讲述作为一名知识工作者如何对知识进行管理以及讲述在对知识进行管理的每个环节中推荐使用的工具。下面用思维导图给出了本文的整体框架：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;说到管理，必然是需要对整个知识获取以及使用保存等环节进行控制。这必然少不了对知识产生，获取，运用等过程进行分解。那么知识的运用流程可以划分成多少个阶段呢。这里，我根据你的知识需要管理这本书，将知识管理划分成以下几个阶段：知识收集、知识加工、知识保存、分享、运用、创新。 知识收集：主要是收集相关的信息，为了采集相关的信息我们需要知道可以从何处获取到相关信息，如何获取。 知识加工：这个阶段主要对知识进行理解，并且做相应的链接。在这个阶段中，我们可能需要知道如何高效的学习，有时候信息可能是一本书籍，或者是好几本书籍，那么我们可能需要学会如何快速的从一本书或者是好几本书中获取我们想要的信息。 知识保存：在对知识进行加工获取到相应的信息之后，我们需要对我们获取到的信息进行总结。 分享：我们为什么要对知识进行分享呢？分享知识有几点好处：1.能够找到志同道合的伙伴。2.可以通过对知识的分享来找到自己的一些盲区，遗漏或者是误解的地方。 运用：知识最终的目的往往是用，学以致用，这才是才是我们学习的最终目标。 创新：创新往往不是凭空产生的，它往往是基于前人的工作，这里知识的积累是必不可少的。 知识收集&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;知识收集主要包括了收集什么，从何处收集，如何收集的问题。这里面收集什么是根据具体情况而定的，这里主要讲下从何处收集，以及如何收集的问题。绝大多数的人都知道我们可以使用搜索引擎从网上获取到我们想要的信息。当时现在搜索引擎有很多，我们在碰到具体的问题的时候该如何选择才能够最好的搜索到我们想要的信息呢。这个问题可能很多人都没有想过。大部分人使用百度这个搜索引擎就以及基本可以解决所有的问题了。但是通过百度这个搜索引擎搜索到的信息很多时候不是最好匹配我们的问题的，特别是对于知识性的问题来说。一般来说百度对于娱乐八卦这方面的信息搜索能力是比较强的，而知识性的信息则比不上谷歌。所有当我们碰到知识性的信息的时候，最好使用谷歌来进行查找。而需要其他一些娱乐八卦相关信息的时候使用百度来进行搜索，当然很多时候在使用一个搜索引擎搜索不到的时候，往往我们都会尝试使用其它搜索引擎来进行搜索，只是当我们知道哪些问题通过哪个搜索引擎能够更快搜索到的时候，我们的效率就会更高。现在谷歌在中国以及没法直接访问了，只能通过购买vpn或者是借助翻墙工具来进行访问。在这里我推荐一款不错的翻墙工具，xxnet。它是一个开源项目，可以从github上获取，具体的配置信息在github上面已经给出了。另一个获取信息的途径是通过知识共享平台来获取，现在有几个很优秀的知识共享平台，比如知乎和简书，在上面分享的信息都很有见地。除了利用互联网，其它获取信息的渠道还有很多，比如一些传统的信息获取方式，通过沟通交流等，其它方面的信息获取方式就不多说了。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另一个问题就是知识收集工具，我们的信息来源是多种多样的，那么我们就相应的需要一个能够收集多个渠道的信息的工具。这里最能满足这个需求的，当属印象笔记。它提供了一个很棒的浏览器插件，印象笔记（剪藏），支持将网页信息获取到印象笔记中，还提供了从邮件，微信，微博中获取信息到印象笔记中的方式。而且它支持多个平台的信息同步，我们可以在电脑、平板、手机上使用印象笔记来收集信息。而且还支持多种类型的信息源，比如图片，网页，声音等。基本上它能将我们产生的各种信息都收集到其中，并且多平台同步。所以作为一个知识收集工具，印象笔记是首选。 知识加工&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在获取到信息之后，我们需要对信息进行整理，从中提炼出有价值的信息，可以实际的给我们所用的。在这个过程中，我们需要将收集到的信息进行分类，并且对信息进行理解、学习，最后可能还需要对相关的信息进行链接，归纳总结等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里面对信息的分类是一个很关键的步骤，如果没有对信息进行分类，那么我们就相当于少了一个标签，想找到我们想要的信息只能从中一件一件的翻，这样的话工作量是很大的。但是如果你将他们进行分类，这样就类似于建立了一个个抽屉，你只需要打开装载你想要的信息的抽屉，就可以找到你想要的信息，这样就可以很快的找到你想要的信息。另一个好处是通过分类这些信息可以真正的用起来，当你只是将收集到的信息堆积起来的时候，信息越堆越多，这样就又回到你最初找到他们的时候的状态，在一大推信息中翻找，看到这种情况，我们往往会放置不管，然后最后把他们丢弃，即使里面确实是有你想要的信息。这一步可以使用印象笔记为每类信息建立笔记本，或者是一个汇总笔记来实现，当然还要记得为每个笔记打上标签，这样的话你想要从你收集到的信息中找到你想要的信息就很快了。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二个可以说是最重要的步骤是对知识进行理解。在很多人的概念中，学习可能就是指这一步骤了。在这一步骤也包含了很多的内容，其中最关键的一点是对学习的理解。对于这些已经有相关的书籍介绍了，其中包括思维导图，如何高效学习，如何阅读一本书等等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在理解了信息之后，我们往往会对信息做相应的链接，归纳总结等，这个步骤是在各种信息发生碰撞之后产生的，也是基于对相关信息进行检索，分类这些步骤。这个过程往往基于你对信息的理解，组合方式。在这里就不做过多的叙述。 知识保存&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在对信息进行加工之后，我们往往会得到一份更加精炼的信息，这些精炼的信息往往是对理解之前的信息的一个归纳总结，往往会以笔记的形式呈现。这个过程仍然推荐印象笔记来对知识进行保存。虽然它的编辑功能用起来并不是那么方便，但是我可以借助另一个工具，markdown标记语言来快速的对信息进行编辑，而不用过多的考虑它的格式，这个也是markdown语言的初衷。具体介绍可以参看以下链接： 分享&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们为什么要进行知识分享呢，知识分享具有如下好处：通过对知识的分享，我们对知识的理解可以更加深刻。 通过知识的分享可以找到志同道合的朋友。*知识的分享也是对自己的一种推销，让招聘者可以更加清晰地看到你的能力。 运用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;学以致用，这才是我们学习的最终目标，所以我们最后要将所学的知识运用起来。这里对于知识如何运用不做过多的阐述，毕竟每个领域知识的运用方式不相同。对于计算机科学领域，知识的运用主要体现在通过程序设计或者是算法设计来满足我们的需求。 创新&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创新是知识管理的一个重要的环节，在我们运用知识解决问题的时候，必然会遇到各种各样的难题，这个时候就需要创新性的思维，来解决相关问题，使其满足我们的需求。对于人工智能算法而言，如何将算法做得更加准确速度更加快以满足实际的应用需求，这就需要大量的创新性工作，而这些创新性工作的基础便是对于已有的知识的学习理解。而创新性的知识之后则又成为了一项成熟的技术或者知识，如此形成一个环，不断迭代，推动着我们整个社会的发展。 相关链接1.开源翻墙工具xxnet https://github.com/XX-net/]]></content>
      <categories>
        <category>工作环境</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fpost%2F4a17b156.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
