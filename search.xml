<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CT-Realistic Lung Nodule Simulation from 3D Conditional Generative Adversarial Networks for Robust Lung Segmentation]]></title>
    <url>%2Fpost%2Fd5dc028e.html</url>
    <content type="text"><![CDATA[该论文发表于MiCCAI2018 动机 在医疗图像领域，数据难获取，而且类内存在着很大的差异。为了缓解数据问题，作者在这篇文章中调查了通过仿真出来的数据，是否能够改善P-HNN模型在肺结节分割任务上的效果。 主要创新点 为了生成仿真数据，作者使用了GAN模型，有效地学习肺结节在3D空间中的属性分布。 为了让仿真的结节能够更好的融入到背景中去，作者使用了真结节的背景信息，即把真结节从图片中抠走。 最后为了能够进一步让结节看起来更加的真实作者提出了一个新颖的multi-mask重构loss. 具体实现 1.3D CGAN 网络结构 生成网络的输入是消除掉中心结节但是包含结节背景信息的图像。通过编码和解码过程，生成网络试图恢复消除掉的中心结节。 判别器的输入包括了扣掉中心结节的图片以及原始图片。 在生成网络的解码器的前两个卷积层作者加入了dropout. 作者在网络中利用strided卷积代替了pooling层。 包括生成网络的编码器，以及判别网络。并在strided 卷积后使用了Leaky relu激活函数。 在生成器的最后一层作者使用了Tanh激活函数 2.模型loss CGAN loss multi-mask L1 loss 这里的M表示消除掉的结节位置，N是对M进行膨胀后的结果。这里的multi-mask是指对消除掉的结节位置的重构loss以及对其膨胀后膨胀位置像素的重构loss，分别赋予不同的loss 权重。比较合适的是3到6个。这里作者给前者赋予1.0，后者赋予5.0. 这个模型的loss由这两部分加权构成 loss包括了两部分，一部分是普通的CGAN loss；另一部分是multi-mask loss。这两部分的权重分别为1.0和100.0. 3.相关参数 作者使用了标准的GAN训练方法，交替优化G和D。 在训练G的时候，作者通过去最大化logD(x,G(x)),而不是去最小化log(1-D(x,G(x)))。 作者使用了Adam优化方法，并设置初始学习率为0.0001，对于生成器动量参数设置为0.5，对于判别器动量参数设置为0.999。 4.数据和结果作者使用了LIDC数据集对GAN模型进行训练1.真实结节从ct图像中crop出来，crop的3个纬度的是结节直径的3到3.5倍大。最后将crop出来的图片缩放到64X64X64。2.消除掉结节的输入图片，由真实结节图片消除掉中心直径为32的球体生成。3.对于结节直接小于5mm的，不用于训练GAN.(c) 用全图的L1loss,不用判别网络(d) 用了GAN和全图的L1 loss(e) 用了GAN和中心消除位置的L1 loss(f) 用了GAN和multi-mask L1 loss 利用训练好的GAN模型生成一些仿真结节，用于fine-tune P-HNN模型P-HNN模型在之前的实验中对于在肺壁的结节分割效果较差，主要原因是训练数据中缺少肺壁附近的结节。 作者首先从LIDC数据集中挑选了34张图，了解数据中缺少的外围结节大致是如何的。 然后从相对健康的CT影像中挑选42个。并从其中随机挑选了30个类似的位置。每个位置距离肺壁距离在8到20mm之间。crop图片的大小为32到80mm之间。 接着将crop的图片缩放到64X64X64。生成仿真数据之后，再将其缩放回去，然后黏贴回原来的位置。 最后利用他们来fine-tune P-HNN模型。 最后的结果显示，生成的结节确实可以提高分割效果。]]></content>
      <categories>
        <category>deep learning</category>
        <category>medical image processing</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>lung nodule</tag>
        <tag>segmentation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[object detection]]></title>
    <url>%2Fpost%2F4ec81054.html</url>
    <content type="text"><![CDATA[object detection（rcnn,the way to endtoend）本文主要简单介绍了rcnn如何一步步改进到支持端到端训练的faster-rcnn。 基础概念 mAP（mean average precision） precision：检测出相关的内容占检测出的内容的比例。 average precision：举个例子，比如说当前文档相关的主题有5个，检测出了3个，其中3个相关的主题rank分别为2,3,4，则这个文档的average precision就是(1/2+2/3+3/4+0+0)/5 。 mAP:则是每个文档的average precision的平均值。这里的文档对应于目标检测的每张图片，而相关主题则对应到图片中目标的个数 IoU（交并比） 两个区域的交集比上两个区域的并集 non maxinum supression 与得分最高的区域的IOU高于某个阈值时，将其排除掉 基于region proposeal加classification这一框架的几个重要工作1.rcnn 几个重要的创新 selection search提取候选区域 利用cnn 提取重要的特征（需要将特征保存到硬盘中，用于svm的训练） 利用svm对不同的候选框进行分类 利用回归来获取更加准确的位置 缺点： 训练需要分成多个阶段完成 训练和存储代价大 检测速度缓慢 2.spp-net 几个重要的贡献 rcnn速度缓慢的原因是它需要分别对每个proposal提取特征，而没有共享计算 输入整张图片，然后利用spp层提取不同尺度大小的featuremap，最后将它们级联起来，最后输出一个特定维度的特征向量。 spp-net使得rcnn在检测的时候提升了10到100倍。训练速度提升了3倍。 缺点 训练仍然需要多个阶段。仍然需要提取特征训练svm； 最后仍然需要利用回归模型来获取更加精确的定位。 需要将特征保存到硬盘中。 网络训练的时候梯度没法穿过spp层。 3.fast rcnn 解决需要将同张图的每个候选区域分别输入网络提取特征的问题直接输入原图，并利用cnn以及roipooling来提取每个roi区域的特征，并利用cnn对每个roi区域进行分类以及定位 roipooling层：单尺度的ssp层，输出特定大小的特征向量，类似于根据情况调整pooling层的kenal size。 多任务的loss：softmax层以及bounding box 回归 几个重要的贡献 提升了训练以及检测的速度。 训练只需要单个阶段就可以完成。使用了多任务的loss层。 可以调整网络的所有层。 不需要将特征保存到硬盘中 缺点： 仍然需要利用selection search 4.faster rcnn 提出了利用PRN来提取候选区域，并让PRN与fast rcnn共享网络。使得目标检测成为真正的一种endtoend的方式，并将速度进一步提升到可以进行实时检测的目的。]]></content>
      <categories>
        <category>deep learning</category>
        <category>object detection</category>
      </categories>
      <tags>
        <tag>object detection</tag>
        <tag>rcnn</tag>
        <tag>spp-net</tag>
        <tag>fast rcnn</tag>
        <tag>faster rcnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime基础用法汇总]]></title>
    <url>%2Fpost%2Ff7b78535.html</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sublime由于支持多种插件的功能扩展，以及其优秀的编辑能力，得到了越来越多人特别是linux平台下的程序开发人员的青睐。但是想要发挥他强大的功能优势，还是需要学习以及熟悉这些功能，在这里整理了网上关于sublime插件基础用法的相关资料，供需要的人查看。sublime简明教程简书上有人整理的sublime学习资源]]></content>
  </entry>
  <entry>
    <title><![CDATA[利用git来管理各种文档]]></title>
    <url>%2Fpost%2F6de20b39.html</url>
    <content type="text"></content>
      <categories>
        <category>工作环境</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[terminator+tmux打造超级终端]]></title>
    <url>%2Fpost%2F12fd4503.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[利用sublime文本编辑工具和markdown标记语言写印象笔记]]></title>
    <url>%2Fpost%2F78cc5777.html</url>
    <content type="text"></content>
      <categories>
        <category>工作环境</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建属于你自己的工作环境]]></title>
    <url>%2Fpost%2Fd9ff40b9.html</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文主要讲述作为一名知识工作者如何对知识进行管理以及讲述在对知识进行管理的每个环节中推荐使用的工具。下面用思维导图给出了本文的整体框架：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;说到管理，必然是需要对整个知识获取以及使用保存等环节进行控制。这必然少不了对知识产生，获取，运用等过程进行分解。那么知识的运用流程可以划分成多少个阶段呢。这里，我根据你的知识需要管理这本书，将知识管理划分成以下几个阶段：知识收集、知识加工、知识保存、分享、运用、创新。 知识收集：主要是收集相关的信息，为了采集相关的信息我们需要知道可以从何处获取到相关信息，如何获取。 知识加工：这个阶段主要对知识进行理解，并且做相应的链接。在这个阶段中，我们可能需要知道如何高效的学习，有时候信息可能是一本书籍，或者是好几本书籍，那么我们可能需要学会如何快速的从一本书或者是好几本书中获取我们想要的信息。 知识保存：在对知识进行加工获取到相应的信息之后，我们需要对我们获取到的信息进行总结。 分享：我们为什么要对知识进行分享呢？分享知识有几点好处：1.能够找到志同道合的伙伴。2.可以通过对知识的分享来找到自己的一些盲区，遗漏或者是误解的地方。 运用：知识最终的目的往往是用，学以致用，这才是才是我们学习的最终目标。 创新：创新往往不是凭空产生的，它往往是基于前人的工作，这里知识的积累是必不可少的。 知识收集&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;知识收集主要包括了收集什么，从何处收集，如何收集的问题。这里面收集什么是根据具体情况而定的，这里主要讲下从何处收集，以及如何收集的问题。绝大多数的人都知道我们可以使用搜索引擎从网上获取到我们想要的信息。当时现在搜索引擎有很多，我们在碰到具体的问题的时候该如何选择才能够最好的搜索到我们想要的信息呢。这个问题可能很多人都没有想过。大部分人使用百度这个搜索引擎就以及基本可以解决所有的问题了。但是通过百度这个搜索引擎搜索到的信息很多时候不是最好匹配我们的问题的，特别是对于知识性的问题来说。一般来说百度对于娱乐八卦这方面的信息搜索能力是比较强的，而知识性的信息则比不上谷歌。所有当我们碰到知识性的信息的时候，最好使用谷歌来进行查找。而需要其他一些娱乐八卦相关信息的时候使用百度来进行搜索，当然很多时候在使用一个搜索引擎搜索不到的时候，往往我们都会尝试使用其它搜索引擎来进行搜索，只是当我们知道哪些问题通过哪个搜索引擎能够更快搜索到的时候，我们的效率就会更高。现在谷歌在中国以及没法直接访问了，只能通过购买vpn或者是借助翻墙工具来进行访问。在这里我推荐一款不错的翻墙工具，xxnet。它是一个开源项目，可以从github上获取，具体的配置信息在github上面已经给出了。另一个获取信息的途径是通过知识共享平台来获取，现在有几个很优秀的知识共享平台，比如知乎和简书，在上面分享的信息都很有见地。除了利用互联网，其它获取信息的渠道还有很多，比如一些传统的信息获取方式，通过沟通交流等，其它方面的信息获取方式就不多说了。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另一个问题就是知识收集工具，我们的信息来源是多种多样的，那么我们就相应的需要一个能够收集多个渠道的信息的工具。这里最能满足这个需求的，当属印象笔记。它提供了一个很棒的浏览器插件，印象笔记（剪藏），支持将网页信息获取到印象笔记中，还提供了从邮件，微信，微博中获取信息到印象笔记中的方式。而且它支持多个平台的信息同步，我们可以在电脑、平板、手机上使用印象笔记来收集信息。而且还支持多种类型的信息源，比如图片，网页，声音等。基本上它能将我们产生的各种信息都收集到其中，并且多平台同步。所以作为一个知识收集工具，印象笔记是首选。 知识加工&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在获取到信息之后，我们需要对信息进行整理，从中提炼出有价值的信息，可以实际的给我们所用的。在这个过程中，我们需要将收集到的信息进行分类，并且对信息进行理解、学习，最后可能还需要对相关的信息进行链接，归纳总结等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里面对信息的分类是一个很关键的步骤，如果没有对信息进行分类，那么我们就相当于少了一个标签，想找到我们想要的信息只能从中一件一件的翻，这样的话工作量是很大的。但是如果你将他们进行分类，这样就类似于建立了一个个抽屉，你只需要打开装载你想要的信息的抽屉，就可以找到你想要的信息，这样就可以很快的找到你想要的信息。另一个好处是通过分类这些信息可以真正的用起来，当你只是将收集到的信息堆积起来的时候，信息越堆越多，这样就又回到你最初找到他们的时候的状态，在一大推信息中翻找，看到这种情况，我们往往会放置不管，然后最后把他们丢弃，即使里面确实是有你想要的信息。这一步可以使用印象笔记为每类信息建立笔记本，或者是一个汇总笔记来实现，当然还要记得为每个笔记打上标签，这样的话你想要从你收集到的信息中找到你想要的信息就很快了。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二个可以说是最重要的步骤是对知识进行理解。在很多人的概念中，学习可能就是指这一步骤了。在这一步骤也包含了很多的内容，其中最关键的一点是对学习的理解。对于这些已经有相关的书籍介绍了，其中包括思维导图，如何高效学习，如何阅读一本书等等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在理解了信息之后，我们往往会对信息做相应的链接，归纳总结等，这个步骤是在各种信息发生碰撞之后产生的，也是基于对相关信息进行检索，分类这些步骤。这个过程往往基于你对信息的理解，组合方式。在这里就不做过多的叙述。 知识保存&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在对信息进行加工之后，我们往往会得到一份更加精炼的信息，这些精炼的信息往往是对理解之前的信息的一个归纳总结，往往会以笔记的形式呈现。这个过程仍然推荐印象笔记来对知识进行保存。虽然它的编辑功能用起来并不是那么方便，但是我可以借助另一个工具，markdown标记语言来快速的对信息进行编辑，而不用过多的考虑它的格式，这个也是markdown语言的初衷。具体介绍可以参看以下链接： 分享&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们为什么要进行知识分享呢，知识分享具有如下好处：通过对知识的分享，我们对知识的理解可以更加深刻。 通过知识的分享可以找到志同道合的朋友。*知识的分享也是对自己的一种推销，让招聘者可以更加清晰地看到你的能力。 运用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;学以致用，这才是我们学习的最终目标，所以我们最后要将所学的知识运用起来。这里对于知识如何运用不做过多的阐述，毕竟每个领域知识的运用方式不相同。对于计算机科学领域，知识的运用主要体现在通过程序设计或者是算法设计来满足我们的需求。 创新&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创新是知识管理的一个重要的环节，在我们运用知识解决问题的时候，必然会遇到各种各样的难题，这个时候就需要创新性的思维，来解决相关问题，使其满足我们的需求。对于人工智能算法而言，如何将算法做得更加准确速度更加快以满足实际的应用需求，这就需要大量的创新性工作，而这些创新性工作的基础便是对于已有的知识的学习理解。而创新性的知识之后则又成为了一项成熟的技术或者知识，如此形成一个环，不断迭代，推动着我们整个社会的发展。 相关链接1.开源翻墙工具xxnet https://github.com/XX-net/]]></content>
      <categories>
        <category>工作环境</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fpost%2F4a17b156.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
